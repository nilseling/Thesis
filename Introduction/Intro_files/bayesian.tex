%!TEX root = ../intro.tex
%******************************
%	 Bayesian approaches
%*****************************

\section{Bayesian approaches to model scRNA-Seq data}

In the last decade, an array of tools to process and analyse scRNA-Seq data have been developed. These methods include tools for data acquisition (e.g.~alignment, de-duplication, quantification), data filtering (e.g.~quality control, normalisation, imputation), cell labelling (e.g.~clustering, classification, ordering) and gene-level analysis (e.g.~differential expression, detection of expression patterns) \citep{Zappia2018}. Extensive comparisons of these methods have been performed for each stage of the analysis pipeline \citep{Saelens2018, Soneson2018}. In this thesis, I will focus on the application and development of Bayesian statistical methodologies designed to characterise cellular heterogeneity using scRNA-Seq data. This section describes key concepts of Bayesian inference and related previous work that serve as a foundation for the results in later chapters.

\subsection{The basics of Bayesian inference}

The main difference between classical and Bayesian inference is the treatment of model parameters. While classical inference considers model parameters as fixed but unknown values, Bayesian approaches treat parameters as random variables for which probability distributions quantify uncertainty \citep{Bernardo2003}. In this context, prior beliefs about the distribution of the model parameter $\omega$ are summarised in the form of a \emph{prior distribution} $\pi(\omega)$. Once the data $D$ is observed, the prior distribution is updated using the Bayes theorem \cite{Bayes1763} to form the posterior distribution $\pi^*(\omega|D)$:

\begin{equation} \label{eq0:Bayes_theorem}
\pi^*(\omega|D)=\frac{L(D|\omega)\pi(\omega)}{L(D)}\text{, where }L(D)=\int_\omega{}L(D|\omega)\pi(\omega)d\omega 
\end{equation}

Here, $L(D|\omega)$ is the likelihood of observing the data given the parameter $\omega$ and $L(D)$ is the marginal likelihood after integrating out the parameter $\omega$. As discussed in \textbf{Section \ref{sec0:prior}}, $L(D)$ does not have a closed form, except for specific prior choices. Despite this, the numerical methods described in \textbf{Section \ref{sec0:posterior_inference}} enable estimating the posterior distribution $\pi^*(\omega|D)$ without the need of calculating $L(D)$.

\newpage

\subsection{Prior distributions}
\label{sec0:prior}

The role of the prior distribution is to incorporate prior knowledge about the model parameters. Using the Bayes theorem, this is then combined with the data to form the posterior distribution. For this purpose, a prior distribution should ideally describe the experimenter's prior knowledge regarding the unknown parameters (e.g.~based on previous experiments). For practical use, the prior distribution can be chosen to form an analytically tractable solution for the integral that is required to calculate $L(D)$. This is achieved by using conjugate prior distributions, for which the prior is of the same family as the posterior distribution. As such, conjugate prior distributions lead to a closed form posterior distribution, which facilitates posterior inference. A list of commonly used conjugate prior distributions can be seen in \textbf{Table \ref{tab0:priors}}.

\begin{table}[hb	]
\centering
\caption{Conjugate prior distributions for common likelihood functions taken from \citep{Fink1997}}
\label{tab0:priors}
\begin{tabular}{l l l}
\toprule
\textbf{Discrete} & &\\
\midrule
\midrule
\textbf{Data generation process} & \textbf{Prior} & \textbf{Posterior} \\ 
\midrule 
Bernoulli & Beta & Beta \\
Poisson & Gamma  & Gamma \\
Negative Binomial & Beta & Beta \\
\midrule
\midrule
\textbf{Continuous} & & \\
\midrule
\midrule
\textbf{Data generation process} & \textbf{Prior} & \textbf{Posterior} \\ 
\midrule
Uniform  & Pareto & Pareto \\ 
Normal (unknown mean) &  Normal  & Normal \\ 
Normal (unknown variance) &  Inverse Gamma  & Inverse Gamma \\ 
Gamma (unknown rate) &  Gamma  & Gamma \\ 
Exponential &  Gamma  & Gamma \\ 
\bottomrule
\end{tabular}
\end{table} 

When prior knowledge of the model parameters is not available, non-informative or objective priors may be used (e.g.~the Jeffreys prior \citep{Jeffreys1946}). However, a detailed discussion regarding such priors is outside the scope of this thesis.

\newpage

\subsection{Posterior inference} \label{sec0:posterior_inference}

Before the availability of computers, research centred around finding pairs of likelihood functions and prior distributions that produce well-defined and tractable solutions for posterior distributions (conjugate priors). More recently, the increase in computing power supported the development of numerical methods to approximate the integrals needed to form posterior distributions \citep{Fink1997}. Numerical approximations are needed when objective priors are used or for models with large complexity. When the model contains multiple parameters, it could be of interest to find univariate marginal posterior densities or multivariate joint marginal posterior densities of model parameters.\\

Multiple numerical approximation strategies have been described including: \emph{Laplace Approximation, Iterative Quadrature, Importance Sampling, Sampling-importance-resampling, and Markov Chain Monte Carlo} \citep{Bernardo2000}. At this point, I will focus on \gls{MCMC} \citep{Metropolis1953, Hastings1970} as a sampling strategy to approximate posterior distributions.

\subsubsection{Markov Chain Monte Carlo}

The idea behind MCMC is to generate a sample of the posterior distribution $\pi^*(\omega|D)$ for $\omega\in\Omega$ when the distribution cannot be obtained directly. For this, a Markov chain with state space $\Omega$ is simulated over $n$ iterations whose equilibrium distribution is $\pi^*(\omega|D)$ \citep{Bernardo2000}. Extensive research led to the development of algorithms that generate this equilibrium distribution \citep{Casella1992, Gelfand1990, Greyer1992, Besag1993, Gelman1992}.
The following two examples of MCMC are commonly used for a range of applications in Bayesian statistics \citep{Bernardo2000}.\\

\textbf{\textit{Gibbs sampling}}\\

We consider a complex model where $\bm{\theta}$ represents the vector of unknown parameters in Bayes theorem. The joint posterior $\pi^*(\bm{\theta}|D)=\pi^*(\theta_1,...,\theta_k|D)$ is not tractable and needs to be numerically approximated. To obtain posterior distributions for each model parameter $\theta_i$, one defines the \emph{full conditional} distribution:

\begin{equation}
\pi^*(\theta_i|D,\theta_j,j\neq{}i), \quad i=1,...,k
\end{equation}

This defines the density of the individual component $\theta_i$ given the data and specified values (current updates) of all other components $\theta_j$ \cite{Geman1984} and can easily be identified from the part of the posterior distribution depending on $\theta_i$ \citep{Bernardo2000}. In each iteration $t$ with $t=1,...,n$ every component $\theta_i,\,{}i=1,...,k$ is updated as followed:

\begin{align*}
\textnormal{draw} \quad  \theta_1^{(t+1)} \quad \textnormal{from} \quad & \pi^*(\theta|D, \theta_2^{(t)},...\theta_k^{(t)})\\
\textnormal{draw} \quad  \theta_2^{(t+1)} \quad \textnormal{from} \quad & \pi^*(\theta|D, \theta_1^{(t+1)},\theta_3^{(t)},...\theta_k^{(t)})\\
&.\\
&.\\
&.\\
\textnormal{draw} \quad  \theta_k^{(t+1)} \quad \textnormal{from}  \quad& \pi^*(\theta|D, \theta_1^{(t+1)},...\theta_{k-1}^{(t+1)})
\end{align*}

For $t\rightarrow{}\infty$ the joint distribution of $(\theta_1,...,\theta_k)$ converge towards the posterior distribution of $\pi^*(\bm{\theta}|D)$ \citep{Roberts1994, Geman1984}. The probability density function of the transition is defined as:

\begin{equation}
p(\theta^t,\theta^{t+1})=\prod_{l=1}^k{}\pi(\theta_l^{t+1}|(\theta_j^t,j>l),(\theta_j^{t+1},j<l),D)
\end{equation}

The implementation of Gibbs sampling is straightforward when the full conditionals have a known form. For other distributions, stochastic simulation techniques can be used.\\

\textbf{\textit{Metropolis-Hastings}}\\

Another commonly used technique is the \emph{Metropolis-Hastings algorithm} \citep{Metropolis1953, Hastings1970} which constructs a Markov chain $\theta_i^1,...,\theta_i^n$ with state space $\Theta$ as follows:\\

Let $q(\theta_i,\theta_i')$ be a transition probability density function given a current state $\theta_i^t=\theta_i$, then the vector $\theta_i'$ represents a proposed possible value for $\theta_i^{t+1}$ \citep{Bernardo2000}. Furthermore, with some probability $\alpha(\theta_i,\theta_i'|\theta_j,j\neq{}i)$ the proposed value $\theta_i'$ is accepted as $\theta_i^{t+1}=\theta_i'$ and otherwise rejected: $\theta_i^{t+1}=\theta_i^t$ \cite{Roberts1994, Hastings1970}. In practice, the update is found as follows:

\begin{enumerate}
\item Sample $\nu\sim\textnormal{Unif(0,1)}$ and a candidate $\theta_i'$ from $q(\theta_i,\theta_i')$.
\item Define

\begin{equation}
\alpha(\theta_i,\theta_i'|\theta_j,j\neq{}i)=\min\left\lbrace{}1,\frac{\pi^*(\theta_i'|D,\theta_j,j\neq{}i)q(\theta_i',\theta_i)}{\pi^*(\theta_i|D,\theta_j,j\neq{}i)q(\theta_i,\theta_i')}\right\rbrace
\end{equation}

\item If $\nu\leq{}\alpha(\theta_i,\theta_i'|\theta_j,j\neq{}i)$, return $\theta_i'$ otherwise return $\theta_i^t$
\end{enumerate}

For this algorithm, the transition probability density $q(\theta_i,\theta_i')$ needs to be chosen. A common choice is a Normal distribution centred at $\theta_i$ where the variance needs to be selected to have some level of optimality in the performance of the algorithm \citep{Roberts2001}. An automated tuning process for the variance of the proposal distribution $q(\theta_i,\theta_i')$ was introduced by Roberts and Rosenthal, 2009 \citep{Roberts2009}. This \emph{adaptive Metropolis-Hastings} algorithm is often used in combination with Gibbs sampling (\emph{adaptive Metropolis-within-Gibbs sampling}) to approximate the posterior distribution of model parameters for complex models \citep{Roberts2009}.\\

\textbf{\textit{Practical considerations}}\\

Once the sampler is chosen, one needs to validate the convergence of the chain. For this, the initial draws of the distribution are discarded (\emph{burn-in}). Within the burn-in period, the autocovariance of the chain decays to a negligible level \citep{Greyer1992}. After burn-in, one can compute the autocorrelation of the chain to assess convergence. The standard deviation of the chain (a first order autoregressive process) is defined as:

\begin{equation}
\sigma=\frac{\sigma^*}{\sqrt{n}}\sqrt{\frac{1+\rho}{1-\rho}}
\end{equation}

where $\sigma^*$ is the posterior standard deviation of $\pi^*(\omega|D)$, $n$ is the sample size and $\rho$ the autocorrelation \citep{Tierney1991}. Therefore, $\sigma$ is minimised when $\rho$ is small. This also supports finding an optimal run length until sufficient mixing is achieved. In practice, storing every 10 or 100 samples reduces autocorrelation of the chain and increases mixing over the parameter space \citep{Greyer1992}. One formal way of assessing the convergence of the chain was introduced by Geweke, 1992. Here, the means of the first 10\% and the last 50\% of the samples are compared. If the means are different, the chain has not yet reached equilibrium \citep{Geweke1992}.

\subsection{Variational Bayes}

When datasets are large and models are complex, the above described MCMC sampling methods are slow to derive posterior distributions. Variational inference is a quicker approach that allows derivation of an approximate posterior distribution by optimisation. The principle of variational inference is to select a member of a family of approximate densities $Q$ by minimising the \gls{KL}:

\begin{equation}
q^\ast(\bm{\theta})=\underset{q(\bm{\theta})\in{}Q}{\textnormal{argmin\,{}KL}}(q(\bm{\theta})||\pi^*(\bm{\theta}|D))
\end{equation}

The posterior distribution is approximated with the optimised member of the family $q^\ast(\bm{\theta})$\citep{Blei2017}. In general, variational inference tends to be faster than MCMC, albeit MCMC allows producing exact samples from the target density \citep{Blei2017}. Therefore, variational inferences is preferred when datasets are large and exact samples are not needed. A common approach to minimise the KL is to maximise the \gls{ELBO} (see e.g.~\citep{Beal2003}) which is defined as:

\begin{equation}
\textnormal{ELBO}(q)=\mathbb{E}[\log(L(D|\bm{\theta})\pi(\bm{\theta}))] - \mathbb{E}[\log(q(\bm{\theta}))]
\end{equation}

Another principle of variational Bayesian approaches is to assume that model parameters are mutually independent so that the \emph{mean-field variational family} of distributions can be chosen for $q(\bm{\theta})$:

\begin{equation}
q(\bm{\theta})=\prod_{j=1}^k{}q_j(\theta_j)
\end{equation}

Here, each model parameter $\theta_j$ is governed by its own variational factor \citep{Blei2017}. One commonly used technique to maximise the ELBO is \emph{\gls{CAVI}}. Similar to Gibbs sampling, CAVI maximises the ELBO for one parameter while keeping all other parameters constant. This is done iteratively until the ELBO converges against a local maximum \citep{Blei2017}. 

\subsection{Bayesian decision theory} \label{sec0:decision}

We assume the data $D$ have arisen under one of the hypotheses $H_1$ or $H_0$ according to $L(D|H_1)$ or $L(D|H_0)$. The data produce posterior probabilities $\pi^*(H_1|D)$ and $\pi^*(H_0|D)$ from prior distributions $\pi(H_1)$ and $\pi(H_0)$. The Bayes factor $B_{10}$ \citep{Jeffreys1961} is defined as the ratio of the posterior odds of $H_1$ to its prior odds:

\begin{equation}
B_{10}=\frac{\pi^*(H_1|D)}{\pi^*(H_0|D)}/{}\frac{\pi(H_1)}{\pi(H_0)}=\frac{L(D|H_1)}{L(D|H_0)}
\end{equation}  

When the hypotheses $H_1$ and $H_0$ are equally probable \emph{a priori}, the Bayes factor is equal to the posterior odds in favour of $H_1$ \citep{Kass1995}. To compute the Bayes factor, one needs to find the marginal likelihoods $L(D|H_1)$ and $L(D|H_0)$, which represents the integrals of the likelihood over all model parameters. When improper priors are used, these marginal likelihoods are intractable and this measure is difficult to compute. \\

Alternatively, when improper priors are used, \emph{tail posterior probabilities} can be computed as a selection rule regarding $H_1$ and $H_0$. Posterior tail probabilities were introduced to test the difference $\delta_g$ in log-expression of gene $i$ between condition $A$ and condition $B$ \citep{Bochkina2007}. Here, the posterior tail probability of $\delta_g$ being larger than a given threshold $\delta_g^{(\alpha)}$ is defined as:

\begin{equation}
\pi(\delta_g,\delta_g^{(\alpha)})=P\left\lbrace|\delta_g|>\delta_g^{(\alpha)}|D\right\rbrace
\end{equation}

In the case of testing changes in mean expression, the difference $\delta_g$ represents the log-fold change in mean expression $\log(\frac{\mu^{(B)}}{\mu^{(A)}})$. In practice, for each iteration of the MCMC, this difference is computed and the tail posterior probability is the fraction of the absolute distance being larger than the threshold. If the tail posterior probability is larger than an evidence threshold (e.g. 80\%) one would reject the null hypothesis $|\delta_g|\leq\delta_g^{(\alpha)}$ \citep{Vallejos2016}. 

\subsection{Modelling scRNA-Seq data}

Several models have been proposed to estimate model parameters based on scRNA-Seq data. A common approach is to model the count data as \gls{NB} distributed \citep{Vallejos2015BASiCS, Risso2018, Lopez2018}. The NB distribution is defined as:

\begin{equation}
f_{NB}(y;\mu,\theta)=\frac{\Gamma(y+\theta)}{\Gamma(\theta)y!}\left(\frac{\theta}{\theta + \mu}\right)^\theta\left(\frac{\mu}{\mu + \theta}\right)^y
\end{equation}

Here, the dispersion of the NB is $\delta=\theta^{-1}$ \cite{Risso2018}. In the case of a hierarchical generative model, the NB can be decomposed into a Poisson distribution with Gamma random effect \cite{Vallejos2015BASiCS}:

\begin{align*}
y|\cdot&\sim{}\textnormal{Poisson}(\nu\mu)\\
\nu|\alpha,\beta&\sim{}\textnormal{Gamma}(\alpha,\beta)
\end{align*}

In some cases \citep{Risso2018, Lopez2018} the NB is extended to account for dropout events in scRNA-Seq data \citep{Kharchenko2015}. The \gls{ZINB} takes the form:

\begin{equation}
f_{ZINB}(y;\mu,\theta,\pi)=\pi\delta_0(y) + (1-\pi)f_{NB}(y;\mu,\theta) 
\end{equation}

where $\delta_0(\cdot)$ is the Dirac function and $\pi\in[0,1]$ is the probability that 0 is observed instead of the count $y$ \citep{Risso2018}. In a hierarchical formulation this can be modelled by adding a Bernoulli distributed random effect:

\begin{align*}
y|\cdot & = 
 \left\lbrace
  \begin{aligned}
    & x && \textnormal{if} \; h = 0,  \\ 
    & 0 && \textnormal{otherwise}    	    
  \end{aligned}
\right.\\
x|\cdot&\sim{}\textnormal{Poisson}(\nu\mu)\\
h & \sim \textnormal{Bernoulli}(\cdot)\\
\nu|\alpha,\beta&\sim{}\textnormal{Gamma}(\alpha,\beta)
\end{align*}

Other approaches model scRNA-Seq counts as log-normal distributed \citep{Azizi2017,Pierson2015}. \Gls{ZIFA} assumes that the data $Y=[y_1,...,y_N]$, where $N$ is the number of samples with $D$ genes, are generated from an unobserved low-dimensional space $Z=[z_1,...,z_N]$ with dimension $K,\,{}K\ll{}D$ \citep{Pierson2015}. The generation process is a linear transformation with added Gaussian noise from the latent space ($N\times{}K$) into the latent high-dimensional gene expression space with dimension $N\times{}D$. Additionally, with some probability being a function of the latent expression level of gene $j$ in cell $i$ $x_{ij}$: $p_0=\exp(-\lambda{}x_{ij}^2)$, a dropout is observed \citep{Pierson2015}. The full model is defined as:

\begin{align*}
y_{ij} & = 
 \left\lbrace
  \begin{aligned}
    & x_{ij} && \textnormal{if} \; h_{ij} = 0,  \\ 
    & 0 && \textnormal{otherwise}    	    
  \end{aligned}
\right.\\
\bm{x}_{i}|\bm{z}_i&\sim{}\textnormal{Normal}(\bm{Az}_i+\bm{\mu},\bm{W})\\
h_{ij}|x_{ij} & \sim \textnormal{Bernoulli}(p_0)\\
\bm{z_i}&\sim{}\textnormal{Normal}(0,\bm{I})
\end{align*} 

Here, $\bm{A}$ denotes a $D\times{}K$ factor loadings matrix, $\bm{\mu}$ a $D\times{}1$ mean vector, $\bm{W}$ a $D\times{}D$ covariance matrix and $\bm{I}$ the $K\times{}K$ identity matrix.

\newpage

\subsection{BASiCS: Bayesian Inference of Single-Cell Sequencing data} 
\label{sec0:BASiCS}

Throughout this thesis, I will use the \gls{BASiCS} framework \citep{Vallejos2015BASiCS, Vallejos2016} to model scRNA-Seq data generated from homogeneous populations of cells and use posterior estimates of the model parameters for down-stream analysis (e.g. normalisation, differential expression testing).\\

In BASiCS, the expression count of gene $i$ ($ \in \{1, \ldots, q\}$) in cell $j$ ($\in \{ 1, \ldots ,n\}$) $X_{ij}$ is a random variable. Compared to bulk RNA-Seq, scRNA-Seq is inherently noisy due to low starting amounts of RNA \citep{Brennecke2013}. To control for technical noise, BASiCS incorporates reads from synthetic RNA spike-ins \citep{Jiang2011}. Here, the first $q_0$ genes are biological and the  remaining $q-q_0$ genes are technical. The expression counts are modelled as NB using a hierarchical formulation:

\begin{equation} 
 X_{ij}|\mu_i,\phi_j,\nu_j,\rho_{ij} \sim
 \left\lbrace
  \begin{aligned}
    &\textnormal{Poisson}(\phi_j\nu_j\mu_i\rho_{ij}), && i=1,...,q_0,j=1,...n;  \\ 
    &\textnormal{Poisson}(\nu_j\mu_i), && i=q_0+1,...,q,j=1,...,n,    	    
  \end{aligned}
\right.
\end{equation} 

In this model, two random effects were added to model the technical and biological part of the over-dispersion:

\begin{equation} 
\nu_j|s_j,\theta \sim \textnormal{Gamma}\left(\frac{1}{\theta},\frac{1}{s_j\theta}\right), \hspace{0.2cm} \rho_{ij}|\delta_i  \sim \textnormal{Gamma}\left(\frac{1}{\delta_i},\frac{1}{\delta_i}\right)\\
\end{equation} 

Here, $\phi_j$ represents a cell-specific normalisation parameter to correct for differences in mRNA content between cells and $s_j$ models cell-specific scale differences affecting all biological and technical genes. Moreover, the random effect $\nu_j$ captures unexplained technical noise that is not accounted for by the normalisation. The strength of this noise is then quantified by a global parameter $\theta$ (shared across all genes and cells). Heterogeneous gene expression across cells is captured by $\rho_{ij}$, whose strength is controlled by gene-specific over-dispersion parameters $\delta_i$. These quantify the excess of variability that is observed with respect to Poisson sampling noise, after accounting for technical noise. Finally, gene-specific parameters $\mu_i$ represent average expression of a gene across cells \textbf{(Fig.~\ref{fig0:BASiCS}A)}. 

\newpage

\begin{figure}[!h]
\centering
\includegraphics[width=\textwidth]{Fig_19.png}
\caption[The BASiCS model]{\textbf{The BASiCS model.}\\
\textbf{(A)} Hierarchical formulation of the negative-binomial model underlying BASiCS visualised for two cells (j and j') and two genes (i and i', gene i' represents a technical spike-in gene). Squared nodes indicate known quantities (observed expression counts and added number of spike-in molecules). Round nodes indicate unknown quantities. Red circles represent unknown model-parameters while black circles indicate the random effects that play intermediate roles effecting expression counts. Adapted from \citep{Vallejos2015BASiCS}, \textbf{(B)} Illustration of the typical confounding effect that is observed between gene-specific estimates of over-dispersion parameters $\delta_i$ and mean expression parameters $\mu_i$.}
\label{fig0:BASiCS}
\end{figure}

Prior specifications for the model parameters are chosen as follows:

\begin{align*}
\mu_i&\sim\textnormal{log-N}(0,a_\mu^2) \quad \textnormal{for}\;{}i=1,...,q_0\\
\delta_i&\sim\textnormal{log-N}(0,a_\delta^2) \quad \textnormal{for}\;{}i=1,...,q_0\\
s_j&\sim\textnormal{Gamma}(a_s,b_s), \quad j=1,...,n\\
\theta&\sim\textnormal{Gamma}(a_\theta,b_\theta)\\
\Phi&\sim{}n\textnormal{Dirichlet}(a_\Phi), \quad \Phi=(\phi_1,...,\phi_n)
\end{align*}

After integrating out the $\rho_{ij}$ to enhance mixing \citep{Vallejos2015BASiCS} the likelihood is defined as:

\begin{align} 
\Lagr = & \left[\prod_{i=1}^{q_0}\prod_{j=1}^n\frac{\Gamma(x_{ij}+\frac{1}{\delta_i})}{\Gamma(\frac{1}{\delta_i})x_{ij}!}\left(\frac{\frac{1}{\delta_i}}{\phi_j\nu_j\mu_i+\frac{1}{\delta_i}}\right)^\frac{1}{\delta_i}\left(\frac{\phi_j\nu_j\mu_i}{\phi_j\nu_j\mu_i+\frac{1}{\delta_i}}\right)^{x_{ij}}\right] \nonumber\\ 
&\times\left[\prod_{i=q_0+1}^{q}\prod_{j=1}^n\frac{(\nu_j\mu_i)^{x_{ij}}}{x_{ij}!}\exp\lbrace-\nu_j\mu_i\rbrace\right]
\end{align} 

\newpage

Given the NB model, the expected biological counts take the form:

\begin{equation}
\mathbb{E}(X_{ij}|\mu_i,\delta_i,\phi_j,s_j,\theta)=\phi_js_j\mu_i
\end{equation}

This formulation can be used to obtain normalised counts. Furthermore, the coefficient of variation is defined as:

\begin{equation}
\textnormal{CV}^2(X_{ij}|\mu_i,\delta_i,\phi_j,s_j,\theta)=\frac{1}{\phi_js_j\mu_i} + \theta + \delta_i(\theta + 1)
\end{equation}

As discussed in Vallejos \emph{et al.}, 2016 \citep{Vallejos2016}, the CV$^2$ is inversely proportional to the mean expression $\mu_i$. Furthermore, $\delta_i$ can be interpreted as the residual CV$^2$ after removing Poisson sampling and residual technical over-dispersion \citep{Vallejos2015BASiCS, Vallejos2016}. We will therefore use $\delta_i$ as a proxy for the biological part of transcriptional variability when modelling scRNA-Seq data.\\

Posterior inference is implemented using adaptive Metropolis-within-Gibbs sampling (see \textbf{Section \ref{sec0:posterior_inference}}) \citep{Vallejos2015BASiCS, Vallejos2016}. Once posterior distributions are obtained, down-stream analyses can be performed. These include: normalisation of expression counts, variance decomposition into biological and technical noise, detection of highly and lowly variable genes and differential mean and differential over-dispersion testing. The latter is done by computing the tail posterior probabilities of the difference in mean expression or over-dispersion between two conditions ($p$ and $p'$) being larger than an evidence threshold $\tau_0$ or $\omega_0$ (see \textbf{Section \ref{sec0:decision}}, and \citep{Bochkina2007, Vallejos2016}):

\begin{align*}
\pi_{ipp'}(\tau_0)&\equiv{}P(|\log(\mu_i^{(p)}/\mu_i^{(p')})|>\tau_0|D)>\alpha_m\\
\pi_{ipp'}(\omega_0)&\equiv{}P(|\log(\delta_i^{(p)}/\delta_i^{(p')})|>\omega_0|D)>\alpha_d
\end{align*}

If the tail posterior probability is larger than a given propability threshold $\alpha_m$ or $\alpha_d$, the gene is considered to be differentially expressed or differentially over-dispersed \citep{Vallejos2016}. The evidence threshold is usually fixed \emph{a priori} and the probability threshold is defined to control the expected false discovery rate (EFDR) to (e.g.) 5\% \cite{Newton2004, Vallejos2016}.\\

As in Vallejos \emph{et al.}, 2016 \citep{Vallejos2016}, estimates of the over-dispersion parameters $\delta_i$ are negatively correlated to mean expression $\mu_i$ \textbf{(Fig.~\ref{fig0:BASiCS}B)} indicating that in homogeneous populations of cells, highly expressed genes tend to be less noisy than lowly expressed genes. This effect confounds differential over-dispersion testing when mean expression changes. Therefore, when assessing changes in over-dispersion, only genes with no changes in mean expression are considered (see Vallejos \emph{et al.}, 2016 \citep{Vallejos2016} and \textbf{Section \ref{sec1:variability}}).  
